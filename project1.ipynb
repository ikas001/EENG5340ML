{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project 1 data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Data\n",
      "(60000, 784) (60000,)\n",
      "test data\n",
      "(10000, 784) (10000,)\n",
      "(60000, 784)\n",
      "Iteration 1, loss = 0.34707208\n",
      "Iteration 2, loss = 0.16803904\n",
      "Iteration 3, loss = 0.12461142\n",
      "Iteration 4, loss = 0.10228343\n",
      "Iteration 5, loss = 0.08809855\n",
      "Iteration 6, loss = 0.07480725\n",
      "Iteration 7, loss = 0.06668371\n",
      "Iteration 8, loss = 0.05893584\n",
      "Iteration 9, loss = 0.05195750\n",
      "Iteration 10, loss = 0.04597532\n",
      "***********1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.988760\n",
      "Test set score: 0.970100\n",
      "Training accuracy using accuracy_score function 0.98876\n",
      "Training accuracy using accuracy_score function 0.9701\n",
      "*****************2\n",
      "[False False False ... False False False]\n",
      "*****************3\n",
      "[ 139  149  233  247  274  320  321  448  449  495  582  613  619  674\n",
      "  684  691  707  720  726  740  760  844  874  883  895  947  951  956\n",
      "  965 1003 1014 1039 1044 1107 1112 1178 1194 1224 1226 1232 1242 1247\n",
      " 1251 1279 1299 1319 1325 1328 1378 1393 1414 1464 1500 1520 1522 1527\n",
      " 1530 1549 1553 1569 1601 1607 1609 1621 1671 1681 1709 1730 1751 1754\n",
      " 1790 1878 1901 1903 1913 1940 1941 1952 1955 1984 2004 2016 2018 2033\n",
      " 2043 2044 2073 2074 2109 2118 2130 2135 2145 2182 2185 2186 2266 2272\n",
      " 2293 2326 2333 2369 2371 2387 2406 2414 2441 2488 2526 2534 2607 2611\n",
      " 2654 2720 2736 2743 2760 2810 2836 2863 2896 2921 2927 2939 2945 2952\n",
      " 2953 3060 3108 3114 3115 3117 3122 3284 3289 3330 3333 3406 3422 3475\n",
      " 3503 3520 3533 3542 3559 3597 3607 3674 3681 3718 3727 3751 3757 3767\n",
      " 3780 3808 3811 3818 3838 3853 3893 3902 3906 3941 3943 3968 3995 4000\n",
      " 4017 4065 4075 4152 4163 4196 4199 4201 4224 4248 4259 4294 4300 4314\n",
      " 4369 4374 4384 4419 4437 4443 4487 4497 4500 4536 4548 4601 4635 4731\n",
      " 4743 4751 4761 4807 4814 4823 4860 4876 4880 4890 4966 4978 4990 5140\n",
      " 5146 5165 5331 5600 5611 5642 5676 5734 5749 5757 5842 5922 5926 5936\n",
      " 5937 5955 5972 5973 6011 6023 6024 6045 6347 6505 6532 6553 6555 6558\n",
      " 6559 6568 6571 6597 6603 6625 6651 6783 6839 7107 7216 7432 7713 7800\n",
      " 7823 7921 7928 7945 8020 8062 8094 8095 8243 8311 8318 8325 8406 8408\n",
      " 8453 8520 8522 8527 9009 9012 9015 9019 9024 9103 9168 9280 9385 9513\n",
      " 9587 9634 9669 9679 9692 9695 9729 9735 9745 9755 9768 9770 9777 9779\n",
      " 9792 9808 9811 9839 9982]\n",
      "(299,)\n",
      "*****************4\n",
      "299\n",
      "*****************5\n",
      "(784,)\n",
      "9\n",
      "*****************6\n",
      "(784,)\n",
      "*****************7\n",
      "4 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import gzip\n",
    "\n",
    "\n",
    "def load_mnist_images(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    # Read the inputs in Yann LeCun's binary format.\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    # The inputs are vectors now, we reshape them to monochrome 2D images,\n",
    "    # following the shape convention: (examples, channels, rows, columns)\n",
    "    data = data.reshape(-1, 784)\n",
    "    # The inputs come as bytes, we convert them to float32 in range [0,1].\n",
    "    # (Actually to range [0, 255/256], for compatibility to the version\n",
    "    # provided at http://deeplearning.net/data/mnist/mnist.pkl.gz.)\n",
    "    return data / np.float32(256)\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    # Read the labels in Yann LeCun's binary format.\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    # The labels are vectors of integers now, that's exactly what we want.\n",
    "    return data\n",
    "\n",
    "X_train = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "y_train = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "X_test = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "y_test = load_mnist_labels('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "print \"train Data\"\n",
    "print X_train.shape,y_train.shape\n",
    "print \"test data\"\n",
    "print X_test.shape, y_test.shape\n",
    "\n",
    "print X_train.shape\n",
    "X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=10, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print '***********1'\n",
    "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, y_test))\n",
    "y_hat=mlp.predict(X_train)\n",
    "print 'Training accuracy using accuracy_score function',accuracy_score(y_train,y_hat)\n",
    "y_hat=mlp.predict(X_test)\n",
    "print 'Training accuracy using accuracy_score function',accuracy_score(y_test,y_hat)\n",
    "\n",
    "print '*****************2'\n",
    "k=y_test!=y_hat\n",
    "print k\n",
    "\n",
    "print '*****************3'\n",
    "itemindex = np.where(k==True)\n",
    "print itemindex[0]\n",
    "print itemindex[0].shape\n",
    "\n",
    "print '*****************4'\n",
    "print len(itemindex[0])\n",
    "\n",
    "random_index_match=1423\n",
    "random_index_no_match=1422\n",
    "\n",
    "print '*****************5'\n",
    "print X_test[random_index_match].shape\n",
    "match_image=np.reshape(X_test[random_index_match],(28,28))\n",
    "plt.imshow(match_image,cmap='gray')\n",
    "\n",
    "print y_test[random_index_match]\n",
    "print '*****************6'\n",
    "print X_test[random_index_no_match].shape\n",
    "no_match_image=np.reshape(X_test[random_index_no_match],(28,28))\n",
    "plt.imshow(no_match_image,cmap='gray')\n",
    "\n",
    "print '*****************7'\n",
    "print y_test[random_index_no_match],y_hat[random_index_no_match]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
